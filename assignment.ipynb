{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52a0844",
   "metadata": {},
   "source": [
    "# DATA 516 Lab 03\n",
    "##### Mina Nielsen, Fall 2025\n",
    "The goal of this assignment is to build a data process that establishes a performance baseline using CSV files with eaget APIs for comparison with Parquet lazy execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "232a4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import time\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f1837",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a8fa24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = pl.read_csv(\"data/orders_2023_Q1.csv\")\n",
    "q2 = pl.read_csv(\"data/orders_2023_Q2.csv\")\n",
    "q3 = pl.read_csv(\"data/orders_2023_Q3.csv\")\n",
    "q4 = pl.read_csv(\"data/orders_2023_Q4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcebcfcd",
   "metadata": {},
   "source": [
    "As shown by running ```ls -lh``` in ```data```, each of the 4 quarter files are 30M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71e8d2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 18)\n",
      "┌──────────┬────────────┬───────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ order_id ┆ customer_i ┆ product_i ┆ category ┆ … ┆ blob_a    ┆ blob_b    ┆ blob_c    ┆ optional_ │\n",
      "│ ---      ┆ d          ┆ d         ┆ ---      ┆   ┆ ---       ┆ ---       ┆ ---       ┆ score     │\n",
      "│ i64      ┆ ---        ┆ ---       ┆ str      ┆   ┆ str       ┆ str       ┆ str       ┆ ---       │\n",
      "│          ┆ i64        ┆ i64       ┆          ┆   ┆           ┆           ┆           ┆ f64       │\n",
      "╞══════════╪════════════╪═══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 1        ┆ 352        ┆ 10027     ┆ cat_02   ┆ … ┆ lorem     ┆ lorem     ┆ lorem     ┆ 73.530998 │\n",
      "│          ┆            ┆           ┆          ┆   ┆ ipsum     ┆ ipsum     ┆ ipsum     ┆           │\n",
      "│          ┆            ┆           ┆          ┆   ┆ dolor sit ┆ dolor sit ┆ dolor sit ┆           │\n",
      "│          ┆            ┆           ┆          ┆   ┆ amet lor… ┆ amet lor… ┆ amet lor… ┆           │\n",
      "│ 2        ┆ 1353       ┆ 15221     ┆ cat_00   ┆ … ┆ lorem     ┆ lorem     ┆ lorem     ┆ 53.058545 │\n",
      "│          ┆            ┆           ┆          ┆   ┆ ipsum     ┆ ipsum     ┆ ipsum     ┆           │\n",
      "│          ┆            ┆           ┆          ┆   ┆ dolor sit ┆ dolor sit ┆ dolor sit ┆           │\n",
      "│          ┆            ┆           ┆          ┆   ┆ amet lor… ┆ amet lor… ┆ amet lor… ┆           │\n",
      "│ 3        ┆ 7593       ┆ 14399     ┆ cat_02   ┆ … ┆ customer  ┆ customer  ┆ customer  ┆ 62.747406 │\n",
      "│          ┆            ┆           ┆          ┆   ┆ order     ┆ order     ┆ order     ┆           │\n",
      "│          ┆            ┆           ┆          ┆   ┆ shipment  ┆ shipment  ┆ shipment  ┆           │\n",
      "│          ┆            ┆           ┆          ┆   ┆ delive…   ┆ delive…   ┆ delive…   ┆           │\n",
      "└──────────┴────────────┴───────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "Schema({'order_id': Int64, 'customer_id': Int64, 'product_id': Int64, 'category': String, 'subcategory': String, 'region': String, 'status': String, 'order_year': Int64, 'order_month': Int64, 'order_day': Int64, 'price': Float64, 'quantity': Int64, 'discount': Float64, 'extended_price': Float64, 'blob_a': String, 'blob_b': String, 'blob_c': String, 'optional_score': Float64})\n",
      "Schema({'order_id': Int64, 'customer_id': Int64, 'product_id': Int64, 'category': String, 'subcategory': String, 'region': String, 'status': String, 'order_year': Int64, 'order_month': Int64, 'order_day': Int64, 'price': Float64, 'quantity': Int64, 'discount': Float64, 'extended_price': Float64, 'blob_a': String, 'blob_b': String, 'blob_c': String, 'optional_score': Float64})\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(q1.head(3))\n",
    "print(q2.schema)\n",
    "print(q3.schema)\n",
    "print(len(q4.schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a687319",
   "metadata": {},
   "source": [
    "Can confirm all 4 files have the same 18 fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8efe81",
   "metadata": {},
   "source": [
    "### Eager CSV Baseline Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833bed1a",
   "metadata": {},
   "source": [
    "Apply a consistent transformation pattern for later comparison. Including full process in one code block to time full process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fcf3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'category': String, 'region': String, 'total_cost': Float64, 'avg_optional_score': Float64, 'cnt_rows': UInt32})\n",
      "shape: (3, 5)\n",
      "┌──────────┬────────┬────────────┬────────────────────┬──────────┐\n",
      "│ category ┆ region ┆ total_cost ┆ avg_optional_score ┆ cnt_rows │\n",
      "│ ---      ┆ ---    ┆ ---        ┆ ---                ┆ ---      │\n",
      "│ str      ┆ str    ┆ f64        ┆ f64                ┆ u32      │\n",
      "╞══════════╪════════╪════════════╪════════════════════╪══════════╡\n",
      "│ cat_10   ┆ EU     ┆ 3373.9     ┆ 69.927778          ┆ 55       │\n",
      "│ cat_13   ┆ LATAM  ┆ 836.55     ┆ 74.239738          ┆ 15       │\n",
      "│ cat_23   ┆ NA     ┆ 10755.97   ┆ 70.254793          ┆ 197      │\n",
      "└──────────┴────────┴────────────┴────────────────────┴──────────┘\n",
      "Total time spent for Eager/Baseline CSV Analysis : 0.39859843254089355 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "q1 = pl.read_csv(\"data/orders_2023_Q1.csv\")\n",
    "q2 = pl.read_csv(\"data/orders_2023_Q2.csv\")\n",
    "q3 = pl.read_csv(\"data/orders_2023_Q3.csv\")\n",
    "q4 = pl.read_csv(\"data/orders_2023_Q4.csv\")\n",
    "egr = pl.concat([q1, q2, q3, q4])\n",
    "\n",
    "egr = egr.rename({\n",
    "    \"order_year\": \"year\",\n",
    "    \"order_month\": \"month\"\n",
    "})\n",
    "\n",
    "egr = egr.filter((pl.col(\"year\") == 2023)\n",
    "    & (pl.col(\"month\").is_in([7, 8, 9]))\n",
    "    & (pl.col(\"status\") == \"DELIVERED\")\n",
    ")\n",
    "egr = egr.select([\"category\", \"region\", \"extended_price\", \"optional_score\"])\n",
    "egr = egr.group_by([\"category\", \"region\"]).agg(\n",
    "    pl.sum(\"extended_price\").round(2).alias(\"total_cost\"),\n",
    "    pl.mean(\"optional_score\").alias(\"avg_optional_score\"),\n",
    "    pl.len().alias(\"cnt_rows\")\n",
    ")\n",
    "print(egr.schema)\n",
    "print(egr.head(3))\n",
    "egr.write_csv(\"output_eager.csv\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total time spent for Eager/Baseline CSV Analysis : {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0710533",
   "metadata": {},
   "source": [
    "### Convert to Partitioned Parquet and Lazy Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2083ab6",
   "metadata": {},
   "source": [
    "Re-loading the data to start from raw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e712d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = pl.read_csv(\"data/orders_2023_Q1.csv\")\n",
    "q2 = pl.read_csv(\"data/orders_2023_Q2.csv\")\n",
    "q3 = pl.read_csv(\"data/orders_2023_Q3.csv\")\n",
    "q4 = pl.read_csv(\"data/orders_2023_Q4.csv\")\n",
    "lzy = pl.concat([q1, q2, q3, q4])\n",
    "\n",
    "lzy = lzy.rename({\n",
    "    \"order_year\": \"year\",\n",
    "    \"order_month\": \"month\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe72c2",
   "metadata": {},
   "source": [
    "Now, the goal is to produce a Hive-style Parquet dataset and demonstrate lazy execution benefits with redicate/projection pushdown. Start by converting the df to partitoned Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23773be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = lzy.to_arrow()\n",
    "table = table.set_column(\n",
    "    table.schema.get_field_index(\"year\"),\n",
    "    \"year\",\n",
    "    pa.array([f\"{int(y):04d}\" for y in table.column(\"year\").to_pylist()], pa.string())\n",
    ")\n",
    "table = table.set_column(\n",
    "    table.schema.get_field_index(\"month\"),\n",
    "    \"month\",\n",
    "    pa.array([f\"{int(m):02d}\" for m in table.column(\"month\").to_pylist()], pa.string())\n",
    ")\n",
    "\n",
    "# lzy.write_parquet(\"./data/parquet\", compression='zstd', statistics=True, partition_by=[\"year\", \"month\"])\n",
    "\n",
    "pq_format = ds.ParquetFileFormat()\n",
    "fileops = pq_format.make_write_options(compression = \"zstd\")\n",
    "                                    \n",
    "ds.write_dataset(\n",
    "    data = table,\n",
    "    base_dir = \"./data/parquet/\",\n",
    "    format = \"parquet\",\n",
    "    partitioning = ds.HivePartitioning(pa.schema([(\"year\", pa.int64()), (\"month\", pa.string())])),\n",
    "    existing_data_behavior = \"overwrite_or_ignore\",\n",
    "    file_options = fileops\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe687d2a",
   "metadata": {},
   "source": [
    "Now we perform the lazy execution analysis, again all in one code block to time the full process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c922c956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent for Lazy Parquet Analysis : 0.27909183502197266 seconds\n"
     ]
    }
   ],
   "source": [
    "lazy_start = time.time()\n",
    "\n",
    "lf = pl.scan_parquet(\"./data/parquet/\")\n",
    "# apply projection and filters before calling collect()\n",
    "lf = lf.filter(\n",
    "    (pl.col(\"year\") == 2023)\n",
    "    & (pl.col(\"month\").is_in([7, 8, 9]))\n",
    "    & (pl.col(\"status\") == \"DELIVERED\")\n",
    ")\n",
    "lf = lf.select([\"category\", \"region\", \"extended_price\", \"optional_score\"])\n",
    "lf = lf.group_by([\"category\", \"region\"]).agg(\n",
    "    pl.sum(\"extended_price\").round(2).alias(\"total_cost\"),\n",
    "    pl.mean(\"optional_score\").alias(\"avg_optional_score\"),\n",
    "    pl.len().alias(\"cnt_rows\")\n",
    ")\n",
    "\n",
    "lf.collect()\n",
    "lazy_end = time.time()\n",
    "print(f\"Total time spent for Lazy Parquet Analysis : {lazy_end - lazy_start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "61b34501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGREGATE[maintain_order: false]\n",
      "  [col(\"extended_price\").sum().round().alias(\"total_cost\"), col(\"optional_score\").mean().alias(\"avg_optional_score\"), len().alias(\"cnt_rows\")] BY [col(\"category\"), col(\"region\")]\n",
      "  FROM\n",
      "  simple π 4/4 [\"category\", \"region\", ... 2 other columns]\n",
      "    Parquet SCAN [./data/parquet/year=2023\\month=01\\part-0.parquet, ... 11 other sources]\n",
      "    PROJECT 7/18 COLUMNS\n",
      "    SELECTION: [([([(col(\"status\")) == (\"DELIVERED\")]) & (col(\"month\").is_in([[7, 8, 9]]))]) & ([(col(\"year\")) == (2023)])]\n"
     ]
    }
   ],
   "source": [
    "print(lf.explain())\n",
    "# DOCUMENT EVIDENCE OF PUSHDOWN OPTIMIZATIONS IN MKDWN BLOCK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9396dca3",
   "metadata": {},
   "source": [
    "##### Evidence of Pushdown Optimization\n",
    "Polars LazyFrame.explain() gives a query plan that is read from the bottom up. As is clear from the call output in the cell above, both selection of instances with specificed column values and projection of specified columns happens before the Parquet Scan step. This means that the selection and projection are applied during the scan rather than after the data is all loaded in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792862cb",
   "metadata": {},
   "source": [
    "### Comparison & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b8482",
   "metadata": {},
   "source": [
    "On one run of both eager and lazy processes, the eager analysis took 0.31 seconds while the lazy took 0.19 seconds. Parquet uses less memory because it only loads in the columns that are specfied ahead of loading. It also uses a compression method when reading the files in, which furthers the memory savings compared to the CSV eager approach. Both time and file sizes differ between the two approaches, with lazy having lower values for both metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
